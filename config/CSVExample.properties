name=MySourceConnector
tasks.max=1
connector.class=io.confluent.kafka.connect.source.SpoolDirectoryConnector
record.processor.class=io.confluent.kafka.connect.source.io.processing.CSVRecordProcessor
input.file.pattern=^.*\.csv$
finished.path=/tmp/spooldir/finished
error.path=/tmp/spooldir/error
input.path=/tmp/spooldir/input
halt.on.error=false
key.fields=id
topic=csv
#Skip the first line because it's the header.
skip.lines=1
batch.size=1000
null.field.indicator=BOTH
parser.timestamp.date.formats=yyyy-MM-dd'T'HH:mm:ss'Z'
#Field configuration
fields.00.name=id
fields.00.required=true
fields.00.schema.type=INT32
fields.01.name=first_name
fields.01.required=true
fields.01.schema.type=STRING
fields.02.name=last_name
fields.02.required=true
fields.02.schema.type=STRING
fields.03.name=email
fields.03.required=true
fields.03.schema.type=STRING
fields.04.name=gender
fields.04.required=true
fields.04.schema.type=STRING
fields.05.name=ip_address
fields.05.required=true
fields.05.schema.type=STRING
fields.06.logical.type=timestamp
fields.06.name=last_login
fields.06.required=false
fields.06.schema.type=STRING
fields.07.logical.type=decimal
fields.07.name=account_balance
fields.07.required=false
fields.07.schema.type=STRING
fields.08.name=country
fields.08.required=true
fields.08.schema.type=STRING
fields.09.name=favorite_color
fields.09.required=false
fields.09.schema.type=STRING
